# ü©∫ Voice2Care ‚Äî Trascrizione, Analisi e Simulazione di Referti Medici

Nel settore sanitario, specialmente in situazioni di emergenza, il personale medico √® spesso costretto a trascrivere manualmente note cliniche ‚Äî un‚Äôattivit√†:

- ‚è±Ô∏è Lenta e dispendiosa in termini di tempo
- ‚ö†Ô∏è Soggetta a errori umani
- üîó Non integrata nei flussi digitali moderni

**Voice2Care** √® un'applicazione full-stack progettata per automatizzare e semplificare la generazione, l‚Äôanalisi e la gestione dei referti clinici, attraverso l‚Äôutilizzo di tecnologie moderne di speech-to-text, intelligenza artificiale generativa (LLM) e interfacce web interattive.

Il sistema consente al personale sanitario di:

- üéôÔ∏è Trascrivere automaticamente note cliniche dettate a voce
- üßæ Estrarre strutture dati cliniche (in formato JSON) da testi non strutturati
- üñ•Ô∏è Visualizzare, modificare e validare i referti attraverso una dashboard user-friendly
- üîä Generare in voce naturale i referti clinici simutali, tramite supporto per sintesi vocale e simulazione di ambienti reali con rumore di fondo
- üìÑ Generare automaticamente PDF strutturati dei referti pronti per l‚Äôarchiviazione o la stampa
- üö® Ricevere notifiche in tempo reale in caso di criticit√† (es. codice rosso)
- üìä Visualizzare analitiche e statistiche aggregate sui dati clinici


Tutto ci√≤ avviene in un ambiente modulare e scalabile, costruito su:

- üß† Backend in FastAPI, che gestisce la logica di business, la trascrizione e l‚Äôinterazione con i modelli LLM
- üñ•Ô∏è Frontend in Streamlit, che fornisce una dashboard interattiva e facile da usare
- üóÇÔ∏è Database MongoDB, per l‚Äôarchiviazione efficiente e strutturata dei dati clinici

Voice2Care nasce dunque per ridurre il carico cognitivo del personale sanitario, minimizzare gli errori legati alla documentazione manuale e aumentare l'efficienza operativa, con un focus particolare su contesti ad alta criticit√† come il Pronto Soccorso.

## ‚öôÔ∏è Installazione (Terminale VS Code)

### 1. Clonare il repository

```bash
git clone https://github.com/simo26/voice2care.git
```
### 2. Creazione ed attivazione di un ambiente virtuale Python

Assicurati di usare Python 3.11 per il corretto funzionamento dei driver MongoDB di Atlas

```bash
python3.11 -m venv .venv
source .venv/bin/activate  # (Linux/macOS)
.venv\Scripts\activate     # (Windows)
```

### 3. Installazione delle dipendenze

```bash
pip install -r requirements.txt
```

‚ö†Ô∏è Nota importante:
Il pacchetto av (richiesto per il modello di faster-whisper) necessita di:

- FFmpeg installato sul sistema
- Strumenti di sviluppo: pkg-config, build-essential, Cython, gcc, ecc.

macOS:

```bash
brew install ffmpeg
brew install pkg-config
pip install cython
```

Windows:

- 1.Scarica FFmpeg e aggiungilo al PATH.
- 2.Installa il compilatore Visual C++ tramite Build Tools for Visual Studio
- 3.Installa Cython:

```bash
pip install cython
```

### 4. Configurazione delle variabili d'ambiente

Crea un file `.env` partendo da quello di esempio `.env.example` fornito nel repository:

```bash
cp .env.example .env  # Su macOS
copy .env.example .env  # Su Windows (cmd)
```

Compila i valori mancanti: 
- HF_TOKEN: https://huggingface.co
- API_KEY_GEMINI: https://aistudio.google.com
- CHAT_ID: l'id della tua chat ottenibile inviando un messaggio al bot @CodiceRossoBot; successivamente estrapola "id" della chat da: https://api.telegram.org/bot7935276594:AAHNX091qdRxR4W9kYyqi7G8H_Y_5f5ADsE/getUpdates
- DB_PASSWORD: Fornita all'interno dello stesso file di esempio

### 5. Configurazione Redis

Per abilitare l'utilizzo di Redis:

#### Windows
- 1.Installa Redis localmente:

```bash
wsl --install
```
Questo installer√† Ubuntu su WSL2 e riavvier√† il computer. 
Dopo il riavvio, segui la configurazione iniziale (nome utente e password).

- 2.Apri Ubuntu (WSL) e aggiorna i pacchetti
  
```bash
sudo apt udapte
sudo apt install redis-server
```

- 3.Avvia Redis

 ```bash
sudo service redis-server start
```

- 3.Verifica che Redis sia attivo

 ```bash
redis-cli ping
```

Risposta attesa: PONG

- 4.Eseguire il file alert_subscriber.py

#### MacOS

- 1.Installa Redis tramite Homebrew
  
 ```bash
brew install redis
```

- 2.Avvia Redis
  
 ```bash
redis-server
```

- 3.Verifica che Redis sia attivo
  
 ```bash
redis-cli ping
```
Risposta attesa: PONG

- 4.Eseguire il file alert_subscriber.py

### 6. ‚öôÔ∏è Avvio del Backend

Il backend FastAPI pu√≤ essere eseguito in due modalit√†, a seconda delle risorse disponibili e della preferenza per modelli remoti o locali:

üîÅ **Opzione 1 ‚Äî API Hugging Face (whisper-large-v3-turbo)**  
Questa modalit√† sfrutta le API degl'Inference Provider di Hugging Face, ideale per ambienti leggeri.
Usa questa modalit√† se vuoi evitare l‚Äôuso locale di modelli pesanti.

```bash
uvicorn backend.main_whisper_api:app --reload
```

‚ö° **Opzione 2 ‚Äî Faster-Whisper "medium" (modello locale)**
Questa modalit√† utilizza Faster-Whisper in esecuzione locale per la trascrizione, sfruttando la potenza della GPU (se disponibile).

```bash
uvicorn backend.main_whisper_model:app --reload
```

Verifica che torch.cuda.is_available() sia True per sfruttare la GPU.

### 7. üéõÔ∏è Avvio del Frontend (Streamlit)

Lancia l‚Äôinterfaccia utente:

```bash
streamlit run app.py
```


All'avvio della dashboard verranno richieste le credenziali di accesso dell'operatore sanitario (medico) che desidera interagire con l'applicativo:

<img width="600" alt="Screenshot della schermata di login" src="https://github.com/user-attachments/assets/3cd851fe-81e9-4724-8b07-c6257f0d8ce3" />

### Credenziali di esempio

Puoi utilizzare le seguenti credenziali per effettuare l'accesso:

- **Email:** `marco.verdi@asl.it`  
  **Password:** `Sicura456`

- **Email:** `giulia.bianchi@asl.it`  
  **Password:** `PasswordMedico123`

